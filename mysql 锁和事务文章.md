[toc]





# 事务

## InnoDB对ACID的支持

|          特性          |                             说明                             | InnoDB支持                                                   |
| :--------------------: | :----------------------------------------------------------: | ------------------------------------------------------------ |
|         原子性         | 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样 | autocommit，commit，rollcack                                 |
|         一致性         | 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。(比如：A向B转账，不可能A扣了钱，B却没有收到) | 双InnoDB写缓冲区，“双写缓冲区”，InnoDB崩溃恢复               |
|         隔离性         | 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。（例：A正在从一张银行卡里面取钱，在A取钱的过程中，B不能向这张银行卡打钱） | 事务隔离级别                                                 |
| 持久性（涉及硬件选购） | 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失 | 双InnoDB写缓冲区，“双写缓冲区”(innodb_flush_log_at_trx_commit 变量。(例如sync_binlog变量,innodb_file_per_table 变量)，存储设备中的写入缓冲区(例如磁盘驱动器、SSD 或 RAID 阵列,存储设备中的电池后备缓存。用于运行 MySQL 的操作系统，特别是它对fsync()系统调用的支持) |



## 隔离级别

#### 不同隔离级别下读读取数据可能出现的情况

```apl
脏读：一个事务处理过程里读取了另一个未提交的事务中的数据
不可重复读：一个事务在它运行期间，两次查找相同的表，出现了不同的数据
幻读：在一个事务中读取到了别的事务插入的数据，导致前后不一致
串行化：既不允许脏读，也不允许不可重复读，并且还不允许幻读
```

<!--<u>**InnoDB使用不同的锁定策略支持这里描述的每个事务隔离级别实现**</u>-->

|           隔离级别           | 说明 | 脏读 | 不可重复读） | 幻读 |
| :--------------------------: | :----------------: | :------------------------------: | :------------------: | :--: |
| 未提交读（Read uncommitted） |  所有事务都可以看到没有提交事务的数据  |        可能        |               可能               |         可能         |
|  已提交读（Read committed）  |  事务成功提交后才可以被查询到  |       不可能       |               可能               |         可能         |
| 可重复读（Repeatable read）  |  同一个事务内多次查询却返回了不同的数据值  |       不可能       |              不可能              |         可能         |
|  可串行化（Serializable ）   | 强制的进行排序，在每个读读数据行上添加共享锁 |      不可能        |              不可能              |        不可能        |

隔离级别是在多个事务同时进行更改和执行查询时微调结果的性能、可靠性、一致性和可再现性之间的平衡的设置

#### 不可重复读和幻读区别

（1）不可重复读是读取了其他事务更改的数据，针对update操作
 解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据

（2）幻读是读取了其他事务新增的数据，针对insert与delete操作
 解决：使用间隙锁，表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据

幻读和不可重复读都是指的一个事务范围内的操作受到其他事务的影响了。只不过幻读是重点在插入和删除，不可重复读重点在修改

## redo log （共享表空间）

innodb通过预写日志（force log at commit）机制实现事务的持久性

优点:日志顺序写速度远远大于数据页随机写磁盘

两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）

redo log写入流程

![18395032-7cb235ab22dcc839](.\img\18395032-7cb235ab22dcc839.webp)

### redo log block

redo log以块为单位进行存储的，每个块占512字节。log buffer、redo log file中，都是这样以512字节的块存储的

redo log block包含4部分：

-  log_block_hdr_no：(4字节)该日志块在redo log buffer中的位置ID
-  log_block_hdr_data_len：(2字节)该log block中已记录的log大小。写满该log block时为0x200，表示512字节
-  log_block_first_rec_group：(2字节)该log block中第一个log的开始偏移位置
-  lock_block_checkpoint_no：(4字节)写入检查点信息的位置

relog block块头的第三部分 log_block_first_rec_group ，因为有时候一个数据页产生的日志量超出了一个日志块，这是需要用多个日志块来记录该页的相关日志。例如，某一数据页产生了552字节的日志量，那么需要占用两个日志块，第一个日志块占用492字节，第二个日志块需要占用60个字节，那么对于第二个日志块来说，它的第一个log的开始位置就是73字节(60+12)。如果该部分的值和 log_block_hdr_data_len 相等，则说明该log block中没有新开始的日志块，即表示该日志块用来延续前一个日志块

默认redolog由ib_logfile0、ib_logfile1组成，以追加写入的方式循环轮训写入。即先在第一个log file（即ib_logfile0）的尾部追加写，直到满了之后向第二个log file（即ib_logfile1）写。当第二个log file满了会清空一部分第一个log file继续写入

#### 刷redo log策略：

1.发出commit动作时。commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制

2.每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关

3.当log buffer中已经使用的内存超过一半时

4.当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置

MySQL支持用户自定义在commit时如何将log buffer中的日志刷log file中。这种控制通过变量 innodb_flush_log_at_trx_commit 的值来决定。该变量有3种值：0、1、2，默认为1。

- 当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差
- 当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据
- 当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk

![733013-20180508104623183-690986409](.\img\733013-20180508104623183-690986409.png)



#### innodb存储引擎中checkpoint：

redolog日志太大，怎么办？

解决问题：1、缩短数据库的恢复时间 2、缓冲池不够用时，将脏页刷新到磁盘 3、重做日志不可用时，刷新脏页

##### 触发逻辑

- sharp checkpoint：在重用redo log文件(例如切换日志文件)的时候，将所有已记录到redo log中对应的脏数据刷到磁盘
- fuzzy checkpoint：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘。有以下几种情况会触发该检查点：
  - master thread checkpoint：由master线程控制，**每秒或每10秒**刷入一定比例的脏页到磁盘
  - flush_lru_list checkpoint：从MySQL5.6开始可通过 innodb_page_cleaners 变量指定专门负责脏页刷盘的page cleaner线程的个数，该线程的目的是为了保证lru列表有可用的空闲页
  - async/sync flush checkpoint：同步刷盘还是异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘
  - dirty page too much checkpoint：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。too much的比例由变量 innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的百分之75后，就强制刷一部分脏页到磁盘

##### 解决问题

- 当数据库发生宕机时，数据库不需要重做所有的日志，因为Checkpoint之前的页都已经刷新回磁盘。数据库只需对Checkpoint后的重做日志进行恢复，这样就大大缩短了恢复的时间
- 当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘
- 当重做日志出现不可用时，因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，重做日志可以被重用的部分是指这些重做日志已经不再需要，当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。如果重做日志还需要使用，那么必须强制Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置

#### Log sequence number日志序列号

LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，lsn占用8个字节。LSN的值会随着日志的写入而逐渐增大

根据LSN，可以获取到几个有用的信息：

1.数据页的版本信息

2.写入的日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量

3.可知道检查点的位置

实际上还可以获得很多隐式的信息

##### innodb从执行修改语句开始：

(1).首先修改内存中的数据页，并在数据页中记录LSN，暂且称之为data_in_buffer_lsn

(2).并且在修改数据页的同时(几乎是同时)向redo log in buffer中写入redo log，并记录下对应的LSN，暂且称之为redo_log_in_buffer_lsn

(3).写完buffer中的日志后，当触发了日志刷盘的几种规则时，会向redo log file on disk刷入重做日志，并在该文件中记下对应的LSN，暂且称之为redo_log_on_disk_lsn

(4).数据页不可能永远只停留在内存中，在某些情况下，会触发checkpoint来将内存中的脏页(数据脏页和日志脏页)刷到磁盘，所以会在本次checkpoint脏页刷盘结束时，在redo log中记录checkpoint的LSN位置，暂且称之为checkpoint_lsn

(5).要记录checkpoint所在位置很快，只需简单的设置一个标志即可，但是刷数据页并不一定很快，例如这一次checkpoint要刷入的数据页非常多。也就是说要刷入所有的数据页需要一定的时间来完成，中途刷入的每个数据页都会记下当前页所在的LSN，暂且称之为data_page_on_disk_lsn

## undo log 日志（共享表空间）

当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录

作用：

- 提供回滚
- 多个行版本控制(MVCC)当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取

#### 记录日志的方式

- insert操作记录delete操作，但是可能只是打delete flag标签，由最终的主线程完成
- delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的
- update分为两种情况：update的列是否是主键列
  - 如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的
  - 如果是主键列，update分两部执行：先删除该行，再插入一行目标行

<!--提交后的undolog不会立即删除，后续事务可能还需要基于mvcc读快照-->



# mysql 锁

## 锁类型

### 类型

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低

- - 这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。
  - 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如Web 应用

- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高

- - 最大程度的支持并发，同时也带来了最大的锁开销
  - 在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的
  - 行级锁只在存储引擎层实现，而Mysql服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统
  
- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## 锁粒度和兼容

### 意向锁

- 实际应用中InnoDB许多行级锁与表级锁共存

- 未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向（在索引树上打一个标记，其他表锁看到意向锁必须等待）

#### 意向锁分类：

- 意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁

- 意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁


#### 意向锁获取

- 事务要获得某些行的S锁，必须先获得表的IS锁
- 事务要获得某些行的X锁，必须先获得表的IX锁


##### 意向锁的兼容

- InnoDB使用**共享锁**，可以提高读读并发
- 为了保证数据强一致，InnoDB使用强**互斥锁**，保证同一行记录修改与删除的串行性
- InnoDB使用**插入意向锁**，可以提高插入并发
- 由于意向锁仅仅表明意向，它其实是比较弱的锁，意向锁之间并不相互互斥，可以并行

|                  | 意向共享锁（IS） | 意向排他锁（IX） | 共享锁（S） | 排他锁（X） |
| :--------------: | :--------------: | :--------------: | :---------: | :---------: |
| 意向共享锁（IS） |       兼容       |       兼容       |    兼容     |   不兼容    |
| 意向排他锁（IX） |       兼容       |       兼容       |   不兼容    |   不兼容    |
|   共享锁（S）    |       兼容       |      不兼容      |    兼容     |   不兼容    |
|   排他锁（X）    |      不兼容      |      不兼容      |   不兼容    |   不兼容    |

### 锁冲突兼容

|                              | Gap(间隙锁) | Insert Intention(插入意向锁) | Record(行锁) | Next-Key |
| :--------------------------: | :---------: | :--------------------------: | :----------: | :------: |
|         Gap(间隙锁)          |    兼容     |             兼容             |     兼容     |   兼容   |
| Insert Intention(插入意向锁) |    冲突     |             兼容             |     兼容     |   冲突   |
|         Record(行锁)         |    兼容     |             兼容             |     冲突     |   冲突   |
|           Next-Key           |    兼容     |             兼容             |     冲突     |   冲突   |



## InnoDB 锁实现方式

#### 行锁

- InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁
- 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁
- 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时
  别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引
- 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点

#### 间隙锁

- 间隙锁的目的是为了防止幻读，其主要通过两个方面实现这个目的：防止间隙内有新数据被插入

- innodb自动使用条件：

  1.事务级别在RR级别下
  2.检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）

- 对记录之间的间隙锁定

#### next-key锁

- next-key锁的目的是解决可重复度
- 实现方案：`间隙锁`+`行锁`

## 隔离级别和锁

### rc更新

|                           更新事务                           |                         更新事务                         |
| :----------------------------------------------------------: | :------------------------------------------------------: |
|                         聚集索引行锁                         |                           等待                           |
|                    范围（聚集索引）Gap锁                     |                范围内等待，范围外直接执行                |
| 无索引（所有记录加锁，不符合记录解锁，符合记录锁定，锁定记录过多会升级为表锁） | 锁定记录等待，非锁定记录执行（锁定记录过多，升级为表锁） |

### rc 插入

|                         更新事务                         | 插入事务 |
| :------------------------------------------------------: | :------: |
|                           行锁                           |  无影响  |
|                     范围（聚集索引）                     |  无影响  |
| 无索引查询（所有记录加锁，不符合记录解锁，符合记录锁定） |  无影响  |



### rr更新

|                           更新事务                           |                         更新事务                         |
| :----------------------------------------------------------: | :------------------------------------------------------: |
|                         聚集索引行锁                         |                           等待                           |
|                  范围（聚集索引）Next-key锁                  |                范围内等待，范围外直接执行                |
| 无索引（所有记录加锁，不符合记录解锁，符合记录锁定，锁定记录过多会升级为表锁） | 锁定记录等待，非锁定记录执行（锁定记录过多，升级为表锁） |

### rr插入

|                           更新事务                           |                         插入事务                         |
| :----------------------------------------------------------: | :------------------------------------------------------: |
|                             行锁                             |                          无影响                          |
|                  范围（聚集索引）Next-key锁                  |                范围内等待，范围外直接执行                |
| 无索引查询（所有记录加锁，不符合记录解锁，符合记录锁定，锁定记录过多会升级为表锁） | 锁定记录等待，非锁定记录执行（锁定记录过多，升级为表锁） |



## 一致性非锁定读原理(MVCC)

多版本并发控制。MVCC是一种并发控制的方法。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读

### 当前读和快照读

- 当前读：读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁
- 快照读：不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本
- MVCC就是为了实现读-写冲突不加锁，而这个读指的就是`快照读`, 而非`当前读`，当前读实际上是一种加锁的操作，是悲观锁的实现

### MVCC原理

依赖记录中的 `3个隐式字段`，`undo日志` ，`Read View` 

### 隐式字段

- DB_TRX_ID：6byte，最近修改(`修改/插入`)事务ID：记录创建这条记录/最后一次修改该记录的事务ID
- DB_ROLL_PTR：7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
- DB_ROW_ID：6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以`DB_ROW_ID`产生一个聚簇索引

### undo日志

- insert undo log
  代表事务在`insert`新记录时产生的`undo log`, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃
- update undo log
  事务在进行`update`或`delete`时产生的`undo log`; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被`purge`线程统一清除

### undolog记录流程

```a
1. 开启事务，修改该行(记录)数据时，数据库会先对该行加`排他锁`
2. 在`undo log`中增加当前行的拷贝副本
3. 拷贝完毕后，修改该行`name`为任树檀，并且修改隐藏字段的事务ID为当前`事务1`的ID, 我们默认从`1`开始，之后递增，回滚指针指向拷贝到`undo log`的副本记录，既表示我的上一个版本就是它
4. 事务提交后，释放锁
```

`执行事务`：

| 序号 |  name  | age  | DB_TRX_ID（事务id） | DB_ROLL_PTR（回滚指针） | DB_ROW_ID（隐藏主键） |
| :--: | :----: | :--: | :-----------------: | :---------------------: | :-------------------: |
|  2   | 任树檀 |  25  |          1          |        0x101212         |           1           |

`undolog日志`:

| 序号 |  name  | age  | DB_TRX_ID（事务id） | DB_ROLL_PTR（回滚指针） | DB_ROW_ID（隐藏主键） |
| :--: | :----: | :--: | :-----------------: | :---------------------: | :-------------------: |
|  1   | 皮皮檀 |  25  |        null         |          null           |           1           |

```
1. 开启事务，修改该行数据，数据库先为该行加锁
2. 把该行数据拷贝到`undo log`中，作为旧记录，发现该行记录已经有`undo log`了，那么最新的旧数据作为链表的表头，插在该行记录的`undo log`最前面
3. 修改该行`age`为18岁，并且修改隐藏字段的事务ID为当前`事务2`的ID, 那就是`2`，回滚指针指向刚刚拷贝到`undo log`的副本记录
4. 事务提交，释放锁
```

`执行事务`：

| 序号 |  name  | age  | DB_TRX_ID（事务id） | DB_ROLL_PTR（回滚指针） | DB_ROW_ID（隐藏主键） |
| :--: | :----: | :--: | :-----------------: | :---------------------: | :-------------------: |
|  3   | 任树檀 |  18  |          2          |        0x101266         |           1           |

`undolog日志`:

| 序号 |  name  | age  | DB_TRX_ID（事务id） | DB_ROLL_PTR（回滚指针） | DB_ROW_ID（隐藏主键） |
| :--: | :----: | :--: | :-----------------: | :---------------------: | :-------------------: |
|  2   | 任树檀 |  25  |          1          |        0x101212         |           1           |
|  1   | 皮皮檀 |  25  |        null         |          null           |           1           |

序号3、2、1通过回滚指针串联起来

### Read View

- 事务进行`快照读`操作的时候生产的`读视图`(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)
- Read View`遵循一个可见性算法，主要是将`要被修改的数据`的最新记录中的`DB_TRX_ID`（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果`DB_TRX_ID`跟Read View的属性做了某些比较，不符合可见性，那就通过`DB_ROLL_PTR`回滚指针去取出`Undo Log`中的`DB_TRX_ID`再比较，即遍历链表的`DB_TRX_ID`（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的`DB_TRX_ID`, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新`老版本

#### ReadView和事务

- read uncommitted隔离级别事务：直接读取记录的最新版本

- serializable隔离级别事务：使用加锁的方式来访问记录

- RC和RR隔离级别事务：需要用到版本链概念，核心问题是如何判断版本链中哪个版本是当前事务可见的

- readview中四个比较重要的概念：

- - m_ids：表示在生成readview时，当前系统中活跃的读写事务id列表
  - min_trx_id：表示在生成readview时，当前系统中活跃的读写事务中最小的事务id，也就是m_ids中最小的值
  - max_trx_id：表示生成readview时，系统中应该分配给下一个事务的id值
  - creator_trx_id：表示生成该readview的事务的事务id

- 有了readview，在访问某条记录时，按照以下步骤判断记录的某个版本是否可见

- - 1、如果被访问版本的trx_id，与readview中的creator_trx_id值相同，表明当前事务在访问自己修改过的记录，该版本可以被当前事务访问

  - 2、如果被访问版本的trx_id，小于readview中的min_trx_id值，表明生成该版本的事务在当前事务生成readview前已经提交，该版本可以被当前事务访问

  - 3、如果被访问版本的trx_id，大于或等于readview中的max_trx_id值，表明生成该版本的事务在当前事务生成readview后才开启，该版本不可以被当前事务访问

  - 4、如果被访问版本的trx_id，值在readview的min_trx_id和max_trx_id之间，就需要判断trx_id属性值是不是在m_ids列表中

  - - 如果在：说明创建readview时生成该版本的事务还是活跃的，该版本不可以被访问
    - 如果不在：说明创建readview时生成该版本的事务已经被提交，该版本可以被访问

- 生成readview时机

- - RC隔离级别：每次读取数据前，都生成一个readview
  - RR隔离级别：在第一次读取数据前，生成一个readview

![image-20220120152901331](.\img\readview.png)



```c++
struct trx_t {
    /* 事务ID */
    trx_id_t    id;        /*!< transaction id */
    /* 一致性读的快照 */
    ReadView*    read_view;    /*!< consistent read view used in the transaction, or NULL if not yet set */
    // 省略一大堆属性...
}

class ReadView {
    /**
     * 创建这个快照的事务ID
     */
    trx_id_t    m_creator_trx_id;
    /**
     * 生成这个快照时处于活跃状态的事务ID的列表，
     * 是个已经排好序的列表
     */
    ids_t        m_ids;
    /** 
     * 高水位线：id大于等于 m_low_limit_id 的事务都不可见。
     * 在生成快照时，它被赋值为“下一个待分配的事务ID”（会大于所有已分配的事务ID）。
     */
    trx_id_t    m_low_limit_id;
    /**
     * 低水位线：id小于m_up_limit_id的事务都不可见。
     * 它是活跃事务ID列表的最小值，在生成快照时，小于m_up_limit_id的事务都已经提交（或者回滚）。
     */
    trx_id_t    m_up_limit_id;

    // 判断事务是否可见的方法
    bool changes_visible(){}
    // 关闭快照的方法
    void close(){}
    // ...
}

/* 判断某个事务的修改对当前事务是否可见 */
bool changes_visible(){
        /**
         * 可见的情况：
         *  1. 小于低水位线，即创建快照时，该事务已经提交(或回滚)
         *  2. 事务ID是当前事务。
         */
        if (id < m_up_limit_id || id == m_creator_trx_id) {
            return(true);
        }
        if (id >= m_low_limit_id) { /* 高于水位线不可见，即创建快照时，该事务还没有提交 */
            return(false);

        } else if (m_ids.empty()) { /* 创建快照时，没有其它活跃的读写事务时，可见 */
            return(true);
        }
        /**
         * 执行到这一步，说明事务ID在低水位和高水位之间，即 id ∈ [m_up_limit_id, m_low_limit_id)
         * 需要判断是否属于在活跃事务列表m_ids中，
         * 如果在，说明创建快照时，该事务处于活跃状态（未提交），修改对当前事务不可见。
         */
        // 获取活跃事务ID列表，并使用二分查找判断事务ID是否在 m_ids中
        const ids_t::value_type*    p = m_ids.data();
        return(!std::binary_search(p, p + m_ids.size(), id));
}
bool lock_clust_rec_cons_read_sees()
{
    // 获取修改这个数据行的事务ID
    trx_id_t    trx_id = row_get_rec_trx_id(rec, index, offsets);

    // 调用 changes_visible() 判断是否可见，如果不可见则取查找undolog
    return(view->changes_visible(trx_id, index->table->name));
}
```

### MVCC整体请求流程

针对记录 `X` 的操作事务（RR或RC隔离级别下）

|  事务0   |  事务1   |  事务2   |  事务3   |          事务4          |
| :------: | :------: | :------: | :------: | :---------------------: |
| 事务结束 | 事务开始 | 事务开始 | 事务开始 |        事务开始         |
|   ...    |    …     |    …     |    …     | 事务2开始后修改且已提交 |
|   ....   |  进行中  |  快照读  |  进行中  |                         |
|   ....   |    …     |    …     |    …     |                         |

当前的`m_low_limit_id` = 4+1=5  、 trx_id_t    m_up_limit_id = 1,readView:[事务1,2,3]

```c
m_low_limit_id = 4+1=5 //下一个事务的id
m_up_limit_id = 1	// 活跃的最小事务id
read_view = [事务1,事务2,事务3] //活跃事务
m_creator_trx_id = 2		// 当前事务
    /**
     * 事务2的可查询情况(事务1,3不修改数据)
     *  RC隔离级别下
     *      可以查到事务4提交的数据
     *  RR隔离级别下
     *      可以查到事务0提交的数据
     *
     * 事务2的可查询情况(事务1,3修改数据)
     *  RC隔离级别下
     *      可以查到事务4的数据
     *  RR隔离级别下
     *      可以查到事务0的数据
     */
```
